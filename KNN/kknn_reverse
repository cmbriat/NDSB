##################
#source file paths
##################
getData.path="C:/Users/cactus/Desktop/kaggle/code/get_data.txt"
getValidationSets.path="C:/Users/cactus/Desktop/kaggle/code/split_then_balance.txt"

#needs to have loaded original dataset, called Data
#needs to have produced trainData, testData
#needs categories, numCat, dist from ValidationSets


##################
#settings
##################
#set k value of KNN:
bestK=700
#when do we use uniform probs?
threshold=0
#assumes "class" is col 1, "image" is col 2
##################

set.seed(1)
library(kknn)

source(getData.path)
source(getValidationSets.path)

testClass=testData[,1]

fit=kknn(class~., trainData[,-2], testData[,-2], k=bestK, distance=2, kernel="optimal", scale=TRUE)
prob.matrix=fit$prob
pred=fit$fitted.values

n=nrow(prob.matrix)
highestProb=rep(0,n)
for (j in 1:n){
  index=which.max(prob.matrix[j,])
  highestProb[j]=prob.matrix[j,index]
}

results=matrix(0, numCat, 4)
rownames(results)=categories
colnames(results)=c("logloss", "accuracy", "size", "conf")

for (i in 1:numCat){
  ind=which(pred==categories[i])
  sum=0
  for (k in ind){
    if (highestProb[k]<threshold){
      p=1/numCat
    }
    else {
      trueClass=testData[k,1]
      p=prob.matrix[k,trueClass]
      p=max(min(p,1-10^(-15)),10^(-15))
    }
    sum=sum+log(p)
  }
  results[i,1]=-1/(length(ind))*sum
  results[i,2]=mean(pred[ind]==testData[ind,1])
  results[i,3]=length(ind)
  results[i,4]=mean(highestProb[ind])
}

print("VS estimates")

write.table(results, "kknn_VS_reverse.txt", sep="\t")
